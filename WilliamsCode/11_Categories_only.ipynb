{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Dho__8LujzzrUpgtuLM_ihY1_N8aeng2","timestamp":1734482628224}],"gpuType":"A100","authorship_tag":"ABX9TyMFD0gdXxIqLAtE/TgvTqqW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# William Goggins - S00248401\n","\n","import os\n","import shutil\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Flatten, Dense\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","# Paths\n","gdrive_csv_path = \"/content/drive/MyDrive/Colab_Files/Test.csv\"\n","content_csv_path = \"/content/ML_CSV_Files/Test.csv\"\n","organised_test_csv_path = \"/content/ML_CSV_Files/organised_test.csv\"\n","original_train_path = \"/root/.cache/kagglehub/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign/versions/1/Train\"\n","filtered_train_path = \"/content/Train_11_Categories\"\n","original_test_path = \"/root/.cache/kagglehub/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign/versions/1/Test\"\n","organised_test_path = \"/content/Test_Organised\"\n","\n","# Setup and Check Google Drive for Test.csv\n","def setup_test_csv():\n","    print(\"[INFO] Mounting Google Drive...\")\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    print(\"[INFO] Google Drive mounted successfully.\")\n","\n","    # Ensure destination directory exists\n","    os.makedirs(os.path.dirname(content_csv_path), exist_ok=True)\n","\n","    if os.path.exists(gdrive_csv_path):\n","        shutil.copy(gdrive_csv_path, content_csv_path)\n","        print(f\"[SUCCESS] Test.csv copied to {content_csv_path}.\")\n","    else:\n","        raise FileNotFoundError(f\"[ERROR] Test.csv not found at {gdrive_csv_path}. Please ensure it exists.\")\n","\n","# Save Organised Test CSV\n","def save_organised_test_csv():\n","    print(\"[INFO] Saving organised test CSV...\")\n","\n","    test_df = pd.read_csv(content_csv_path)\n","    valid_classes = list(range(11))  # Classes 0 to 10\n","\n","    # Filter for valid classes and save\n","    test_df_filtered = test_df[test_df['ClassId'].isin(valid_classes)]\n","    test_df_filtered.to_csv(organised_test_csv_path, index=False)\n","\n","    print(f\"[SUCCESS] Organised test CSV saved to {organised_test_csv_path}.\")\n","\n","# Reorganise Training Data for Classes 0–10\n","def setup_kaggle_dataset():\n","    print(\"[INFO] Checking for Kaggle dataset...\")\n","    dataset_path = os.path.dirname(original_train_path)\n","\n","    if not os.path.exists(dataset_path):\n","        print(\"[INFO] Kaggle dataset not found. Downloading...\")\n","        import kagglehub\n","        kagglehub.dataset_download(\"meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\")\n","        print(\"[SUCCESS] Kaggle dataset downloaded successfully.\")\n","    else:\n","        print(\"[INFO] Kaggle dataset already exists.\")\n","\n","def filter_train_data():\n","    print(\"[INFO] Filtering training data for classes 0–10...\")\n","\n","    # Ensure dataset is downloaded\n","    setup_kaggle_dataset()\n","    os.makedirs(filtered_train_path, exist_ok=True)\n","\n","    valid_classes = [str(i) for i in range(11)]  # Classes 0 to 10\n","    for class_id in valid_classes:\n","        src_class_dir = os.path.join(original_train_path, class_id)\n","        dst_class_dir = os.path.join(filtered_train_path, class_id)\n","\n","        if os.path.exists(src_class_dir):\n","            if not os.path.exists(dst_class_dir):\n","                shutil.copytree(src_class_dir, dst_class_dir)\n","        else:\n","            print(f\"[WARNING] Class {class_id} not found in the training dataset.\")\n","\n","    print(\"[SUCCESS] Training data filtered for classes 0–10.\")\n","\n","# Reorganise Test Dataset\n","def reorganise_test_csv():\n","    print(\"[INFO] Reorganising test dataset...\")\n","\n","    # Load the organised test CSV file\n","    test_df_filtered = pd.read_csv(organised_test_csv_path)\n","\n","    # Clear the target directory completely\n","    if os.path.exists(organised_test_path):\n","        shutil.rmtree(organised_test_path)  # Remove all files and folders\n","    os.makedirs(organised_test_path, exist_ok=True)\n","\n","    # Organise files by class\n","    valid_classes = list(range(11))  # Ensure only classes 0-10\n","    for class_id in valid_classes:\n","        class_dir = os.path.join(organised_test_path, str(class_id))\n","        os.makedirs(class_dir, exist_ok=True)\n","\n","        class_files = test_df_filtered[test_df_filtered['ClassId'] == class_id]\n","        for _, row in class_files.iterrows():\n","            src_path = os.path.join(original_test_path, os.path.basename(row['Path']))\n","            dst_path = os.path.join(class_dir, os.path.basename(row['Path']))\n","\n","            if os.path.exists(src_path):\n","                shutil.copy(src_path, dst_path)\n","            else:\n","                print(f\"[WARNING] Missing file: {src_path}\")\n","\n","    print(f\"[SUCCESS] Test dataset reorganised and saved to {organised_test_path}.\")\n","\n","# Sanity Check for Class Alignment\n","def verify_class_directories():\n","    print(\"[INFO] Verifying class directories...\")\n","\n","    train_classes = sorted([d for d in os.listdir(filtered_train_path) if os.path.isdir(os.path.join(filtered_train_path, d))])\n","    test_classes = sorted([d for d in os.listdir(organised_test_path) if os.path.isdir(os.path.join(organised_test_path, d))])\n","\n","    print(f\"[INFO] Training classes: {train_classes}\")\n","    print(f\"[INFO] Test classes: {test_classes}\")\n","\n","    if train_classes != test_classes:\n","        raise ValueError(f\"[ERROR] Class mismatch! Training classes: {train_classes}, Test classes: {test_classes}\")\n","    else:\n","        print(\"[SUCCESS] Training and test class directories are aligned.\")\n","\n","# Initialise Data Generators\n","def initialise_data_generators():\n","    print(\"[INFO] Initialising data generators...\")\n","    train_datagen = ImageDataGenerator(rescale=1.0 / 255, validation_split=0.2)\n","    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n","\n","    train_generator = train_datagen.flow_from_directory(\n","        filtered_train_path,\n","        target_size=(224, 224),\n","        batch_size=64,\n","        class_mode=\"categorical\",\n","        subset=\"training\"\n","    )\n","\n","    validation_generator = train_datagen.flow_from_directory(\n","        filtered_train_path,\n","        target_size=(224, 224),\n","        batch_size=64,\n","        class_mode=\"categorical\",\n","        subset=\"validation\"\n","    )\n","\n","    test_generator = test_datagen.flow_from_directory(\n","        organised_test_path,\n","        target_size=(224, 224),\n","        batch_size=64,\n","        class_mode=\"categorical\",\n","        shuffle=False\n","    )\n","\n","    return train_generator, validation_generator, test_generator\n","\n","# Build the Model\n","def build_model():\n","    print(\"[INFO] Building the model...\")\n","    base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n","    base_model.trainable = False\n","\n","    x = base_model.output\n","    x = Flatten()(x)\n","    x = Dense(128, activation=\"relu\")(x)\n","    x = Dense(64, activation=\"relu\")(x)\n","    predictions = Dense(11, activation=\"softmax\")(x)\n","\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","    return model\n","\n","# Train the Model\n","def train_model(model, train_generator, validation_generator):\n","    print(\"[INFO] Training the model...\")\n","    callbacks = [\n","        EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n","        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=2, min_lr=1e-6)\n","    ]\n","\n","    history = model.fit(\n","        train_generator,\n","        validation_data=validation_generator,\n","        epochs=30,\n","        callbacks=callbacks\n","    )\n","\n","    return history\n","\n","# Evaluate the Model\n","def evaluate_model(model, test_generator):\n","    print(\"[INFO] Evaluating the model...\")\n","    test_loss, test_accuracy = model.evaluate(test_generator)\n","    print(f\"Test Accuracy: {test_accuracy:.2f}, Test Loss: {test_loss:.2f}\")\n","\n","# Main Execution\n","if __name__ == \"__main__\":\n","    setup_test_csv()                 # Ensure Test.csv is ready\n","    save_organised_test_csv()        # Save organised test CSV\n","    filter_train_data()              # Step 3: Prepare training data for classes 0–10\n","    reorganise_test_csv()            # Step 4: Reorganise test data for classes 0–10\n","    verify_class_directories()       # Verify class alignment before training\n","\n","    train_gen, val_gen, test_gen = initialise_data_generators()  # Initialise data generators\n","    model = build_model()                                        # Build model\n","    train_model(model, train_gen, val_gen)                      # Train model\n","    evaluate_model(model, test_gen)                             # Evaluate model\n","\n","    model.save(\"gtsrb_model.h5\")\n","    print(\"[SUCCESS] Model saved as 'gtsrb_model.h5'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pis1h4vaMKHo","executionInfo":{"status":"ok","timestamp":1734482484483,"user_tz":0,"elapsed":353607,"user":{"displayName":"William Goggins","userId":"14974217347884021903"}},"outputId":"8345367b-cc89-4e3a-e64c-0bc08d5fad6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Mounting Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[INFO] Google Drive mounted successfully.\n","[SUCCESS] Test.csv copied to /content/ML_CSV_Files/Test.csv.\n","[INFO] Saving organised test CSV...\n","[SUCCESS] Organised test CSV saved to /content/ML_CSV_Files/organised_test.csv.\n","[INFO] Filtering training data for classes 0–10...\n","[INFO] Checking for Kaggle dataset...\n","[INFO] Kaggle dataset not found. Downloading...\n","Downloading from https://www.kaggle.com/api/v1/datasets/download/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 612M/612M [00:29<00:00, 21.7MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["[SUCCESS] Kaggle dataset downloaded successfully.\n","[SUCCESS] Training data filtered for classes 0–10.\n","[INFO] Reorganising test dataset...\n","[SUCCESS] Test dataset reorganised and saved to /content/Test_Organised.\n","[INFO] Verifying class directories...\n","[INFO] Training classes: ['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9']\n","[INFO] Test classes: ['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9']\n","[SUCCESS] Training and test class directories are aligned.\n","[INFO] Initialising data generators...\n","Found 13344 images belonging to 11 classes.\n","Found 3336 images belonging to 11 classes.\n","Found 5460 images belonging to 11 classes.\n","[INFO] Building the model...\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n","[INFO] Training the model...\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 123ms/step - accuracy: 0.3785 - loss: 1.8502 - val_accuracy: 0.4910 - val_loss: 1.5099 - learning_rate: 1.0000e-04\n","Epoch 2/30\n","\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.7062 - loss: 1.0014 - val_accuracy: 0.5830 - val_loss: 1.3156 - learning_rate: 1.0000e-04\n","Epoch 3/30\n","\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.7934 - loss: 0.7546 - val_accuracy: 0.5917 - val_loss: 1.2618 - learning_rate: 1.0000e-04\n","Epoch 4/30\n","\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.8450 - loss: 0.5789 - val_accuracy: 0.5995 - val_loss: 1.2306 - learning_rate: 1.0000e-04\n","Epoch 5/30\n","\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.8744 - loss: 0.4840 - val_accuracy: 0.5980 - val_loss: 1.2310 - learning_rate: 1.0000e-04\n","Epoch 6/30\n","\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.8953 - loss: 0.4082 - val_accuracy: 0.6244 - val_loss: 1.1305 - learning_rate: 1.0000e-04\n","Epoch 7/30\n","\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.9095 - loss: 0.3553 - val_accuracy: 0.6388 - val_loss: 1.1003 - learning_rate: 1.0000e-04\n","Epoch 8/30\n","\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.9284 - loss: 0.3065 - val_accuracy: 0.6463 - val_loss: 1.1178 - learning_rate: 1.0000e-04\n","Epoch 9/30\n","\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.9276 - loss: 0.2844 - val_accuracy: 0.6526 - val_loss: 1.1024 - learning_rate: 1.0000e-04\n","Epoch 10/30\n","\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.9476 - loss: 0.2423 - val_accuracy: 0.6811 - val_loss: 1.0501 - learning_rate: 2.0000e-05\n","Epoch 11/30\n","\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.9500 - loss: 0.2286 - val_accuracy: 0.6844 - val_loss: 1.0358 - learning_rate: 2.0000e-05\n","Epoch 12/30\n","\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.9486 - loss: 0.2287 - val_accuracy: 0.6766 - val_loss: 1.0430 - learning_rate: 2.0000e-05\n","Epoch 13/30\n","\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - accuracy: 0.9534 - loss: 0.2181 - val_accuracy: 0.6748 - val_loss: 1.0384 - learning_rate: 2.0000e-05\n","Epoch 14/30\n","\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.9522 - loss: 0.2177 - val_accuracy: 0.6796 - val_loss: 1.0463 - learning_rate: 4.0000e-06\n","[INFO] Evaluating the model...\n","\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - accuracy: 0.7823 - loss: 0.7204\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.74, Test Loss: 0.86\n","[SUCCESS] Model saved as 'gtsrb_model.h5'.\n"]}]}]}